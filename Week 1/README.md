# ðŸš€ Week 1 

## ðŸ‘‰ Day 1

### Topic 

- Perceptron and Modern Perceptron

### What I Learned

- What is perceptron?
- Gemotric view of perceptron
- Perceptron as a model
- Limitations of Perceptron

### Practical Implementaton

- Implemented the perceptron using PyTorch nn Module
- The modern perceptron using sigmoid function and Binary Cross Entropy.
- The scatter plot which tells how data is scattered
- The plot which shows the linear line which seperated the classes.
- Finally , The output with 200 epochs and 0.3 learning rate

## ðŸ‘‰ Day 2

### Topic

- Bank Churn Prediction using Multi-Layer Perceptron (MLP)

### What I Learned

- What is a Multi-Layer Perceptron (MLP)
- How MLP differs from a simple perceptron
- Why MLP is powerful for learning non-linear decision boundaries
- The role of activation functions, hidden layers, backpropagation, and optimizers in MLP
- Why MLPs are suitable for structured/tabular data like customer churn prediction
- The challenge of class imbalance and why evaluation metrics beyond accuracy (Precision, Recall, F1) are important

### Practical Implementation

- Performed scaling and encoding on the dataset
- Explored data distributions and patterns using visualizations
- Plotted countplots for exited vs gender and geography
- Built and trained an MLP model using PyTorch
- Evaluated the model on Accuracy, Precision, Recall, and F1-score

### Results

- Test Accuracy: 0.8640
- Test Precision: 0.8111
- Test Recall: 0.4324
- Test F1-Score: 0.5641


## ðŸ‘‰ Day 3

### Topic

- Scatter Plot using Matplotlib and seaborn

### what I learned

- what is scatter plot?
- How to create a scatter plot using matplotlib and seaborn
- When to use?
- Where to use?

### Practical Implementation

- Basic scatter plot
- markers
- colors
- transparency
- colormap
- Adding Trend line


## ðŸ‘‰ Day 4

### Topic

- Gradient descent Algorithm

### What I Learned

- What is Grdaient descent?
- Why we use it?
- Mathematical Intution
- Calculating slopes and intercepts
- Things affect gradient descent like dataset, learning rate, epochs

### Practical Implementation
- Implemented gradient descent using linear regression
- Created hyperbola to see the loss in 3D
- understanding epochs and learning rate


## ðŸ‘‰ Day 5

### Topic

- Types of Gradient Descent Algorithms

### What I Learned

- Types of Gradient Descent Algorithms

  - Batch Gradient Descent
  - Stochastic Gradient Descent
  - Mini Batch Gradient Descent
- Advantages of every algorithm
- Disadvantages of every algorithm
- Where to use?
- Mathematical Intution of every algorithm
- Grpahical Intution of every algorithm

### Practical Implementation

- Implement all the types of Gradient Descent algorthims from scratch
- Understood epoches and learning rate by implementing and testing algorithms
- Observed the graphs obtained by them
- r2 score fluctuation in different algorithms


## ðŸ‘‰ Day 6

- Backpropagation in Neural Networks

### What I Learned

- what is backkproagation?
- why we use it?
- mathematical intution of backpropagation
- Understood how we can use it with different optimizers

## Practical Implementation

- Implemented backpropagtion from scratch
- Using numpy and pandas I craeted neurons and parameters without using frameworks
- Observed how the loss reducing by tuning learning rate and epochs


## ðŸ‘‰ Day 7

- Intoverts and Extroverts - Logistic Regression

### What I Learned

- About Logostic Regression
- Mathematical Intution

### Practical Implementation

- Implemented Introvertes to extroverts project using Linear regression
- Did Data cleaning, Data Visualization, Data Scaling, Data Encoding, and other related to pipeline
- Trained the model
- Predictions using Model

### Results : 
- Accuracy Score (without Tuning) : 0.968421044218223
- Accuracy Score (with Tuning)    : 0.968421052631579
